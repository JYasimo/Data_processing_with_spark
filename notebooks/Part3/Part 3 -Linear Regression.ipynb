{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d2fc91c-fbcc-493d-adbe-ed9bee698156",
     "showTitle": true,
     "title": "Linear Regression"
    }
   },
   "outputs": [],
   "source": [
    "#reading file from dbfs\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "df_path= \"/dbfs/mnt/bde2/combined_df\"\n",
    "combined_df= spark.read.parquet(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fed1bcb4-5459-4150-92de-53965b83d0c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[30]: ['VendorID',\n 'tpep_pickup_datetime',\n 'tpep_dropoff_datetime',\n 'store_and_fwd_flag',\n 'RatecodeID',\n 'PULocationID',\n 'DOLocationID',\n 'passenger_count',\n 'trip_distance',\n 'fare_amount',\n 'extra',\n 'mta_tax',\n 'tip_amount',\n 'tolls_amount',\n 'ehail_fee',\n 'improvement_surcharge',\n 'total_amount',\n 'payment_type',\n 'trip_type',\n 'congestion_surcharge',\n 'year',\n 'weekday',\n 'hour',\n 'month',\n 'day_of_year',\n 'trip_duration_sec',\n 'trip_distance_km',\n 'trip_duration_min',\n 'speed',\n 'Borough_pu',\n 'Zone_pu',\n 'service_zone_pu',\n 'Borough_do',\n 'Zone_do',\n 'service_zone_do',\n 'airport',\n 'airport_fee',\n 'colour']"
     ]
    }
   ],
   "source": [
    "#number of columns \n",
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a92411b-4b58-4577-ae60-94f4f21b7915",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b83a268-b8ba-4549-80ef-7909e07955ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Copy df into new df called combined_df_cleaned\n",
    "combined_df_cleaned = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eb01dc8-2be5-419d-8efc-444b05af2ae3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['fare_amount', 'trip_duration_sec', 'trip_distance']\n",
    "\n",
    "# Drop the specified columns using the `select` method\n",
    "combined_df_cleaned = combined_df_cleaned.select([col for col in combined_df_cleaned.columns if col not in columns_to_drop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7caccb11-277e-4943-9fa2-fa0c76fe0acc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# wanted columns\n",
    "cols_list=[\n",
    "  'weekday',\n",
    " 'hour',\n",
    " 'year',\n",
    " 'month',\n",
    " 'trip_distance_km',\n",
    " 'trip_duration_min',\n",
    " 'total_amount',\n",
    " 'speed',\n",
    " 'Zone_pu']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb46ef79-b7a3-4dc8-a349-27db1fe2d1ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#subset df\n",
    "combined_df_cleaned = combined_df_cleaned.select(cols_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb109139-ea73-4915-ba13-11c9513688ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "###Start small to build and validate your code before running on the entire dataset.##\n",
    "######################################################################################\n",
    "\n",
    "num_cols = [\n",
    " 'weekday',\n",
    " 'hour',\n",
    " 'year',\n",
    " 'month',\n",
    " 'trip_distance_km',\n",
    " 'trip_duration_min',\n",
    " 'speed']\n",
    "\n",
    "\n",
    "\n",
    "cat_cols =[\n",
    "'Zone_pu'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94f748f7-bba3-4610-ae51-2909b1058047",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+-----+------------------+------------------+------------+------------------+--------------------+\n|weekday|hour|year|month|  trip_distance_km| trip_duration_min|total_amount|             speed|             Zone_pu|\n+-------+----+----+-----+------------------+------------------+------------+------------------+--------------------+\n|      6|   0|2015|    5|1.7541806000000002| 5.083333333333333|         7.8| 20.70508249180328|Williamsburg (Nor...|\n|      6|   0|2015|    5|         9.2215182|28.816666666666666|       27.96|19.200384916136496|Williamsburg (Nor...|\n|      6|   0|2015|    5|          3.781949|             10.35|        10.8| 21.92434202898551|   East Williamsburg|\n|      6|   0|2015|    5|         4.3130312|             12.65|       15.38|20.457064980237153|      Bushwick South|\n|      6|   0|2015|    5| 7.628271600000001|25.083333333333332|        20.8|18.247028411960137|Williamsburg (Nor...|\n|      6|   0|2015|    5|        10.4124298| 42.56666666666667|        30.8|14.676878339859046|             Bedford|\n|      6|   0|2015|    5|          7.885766|              16.6|       22.56|28.502768674698796|Williamsburg (Nor...|\n|      6|   0|2015|    5|         6.4212666|19.116666666666667|       21.36| 20.15393178727114|          Park Slope|\n|      6|   0|2015|    5|1.9312079999999998| 6.116666666666666|         7.8|18.943729700272478|    Hamilton Heights|\n|      6|   0|2015|    5|1.2874720000000002|3.1166666666666667|         5.8|24.785557219251338|        Forest Hills|\n|      6|   0|2015|    5|        13.5345494|              30.9|        38.5|26.280678446601943|Williamsburg (Nor...|\n|      6|   0|2015|    5| 7.322496999999999|19.433333333333334|       21.96|22.608052487135502|      Bushwick North|\n|      6|   0|2015|    5|4.6348991999999996|14.916666666666666|        13.8|18.643169966480443|  South Williamsburg|\n|      6|   0|2015|    5|         6.2603326|18.283333333333335|        16.8|20.544391394712854|          Greenpoint|\n|      6|   0|2015|    5|          5.713157|             13.15|        17.8|26.067636501901138|Williamsburg (Nor...|\n|      6|   0|2015|    5|1.2874720000000002| 3.966666666666667|         6.3|19.474366386554625|             Astoria|\n|      6|   0|2015|    5|2.2530759999999996| 8.416666666666666|         9.3|16.061531881188117|            Elmhurst|\n|      6|   0|2015|    5|3.1703997999999998| 8.916666666666666|         9.8| 21.33353136448598|Van Cortlandt Vil...|\n|      6|   0|2015|    5|         2.5105704| 7.533333333333333|         8.8|19.995693451327433|University Height...|\n|      6|   0|2015|    5|2.2530759999999996| 4.083333333333333|         8.3| 33.10642285714285|             Bedford|\n+-------+----+----+-----+------------------+------------------+------------+------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Subset the dataframe with the columns list cols_list\n",
    "combined_df=combined_df.select(cols_list)\n",
    "combined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94e4d8b4-0da8-462f-ae3e-e8d7056cab90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "#split the data\n",
    "train_df = combined_df_cleaned.filter(\n",
    "    (col(\"tpep_pickup_datetime\") >= \"2020-01-01\") &\n",
    "    (col(\"tpep_pickup_datetime\") < \"2022-12-31\")\n",
    ")\n",
    "\n",
    "# only keep data after 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1391188-dd67-49ac-b2f2-cd1df1fc9ea2",
     "showTitle": true,
     "title": "Pipeline"
    }
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "#create empty stage\n",
    "stages = []\n",
    "\n",
    "#Iterate through cat_cols and instantiate StringIndexer and OneHotEncoder for each column and them to stages\n",
    "for cat_col in cat_cols:\n",
    "    col_indexer = StringIndexer(inputCol=cat_col, outputCol=f\"{cat_col}_ind\")\n",
    "    col_encoder = OneHotEncoder(inputCols=[f\"{cat_col}_ind\"], outputCols=[f\"{cat_col}_ohe\"])\n",
    "    stages += [col_indexer, col_encoder]\n",
    "\n",
    "#Create a new list called cat_cols_ohe that will add the suffix _ohe to each element of cat_cols\n",
    "cat_cols_ohe = [f\"{cat_col}_ohe\" for cat_col in cat_cols]\n",
    "\n",
    "#initiate vector assembler\n",
    "assembler = VectorAssembler(inputCols=cat_cols_ohe + num_cols, outputCol=\"features\")\n",
    "\n",
    "#Add assembler to stages\n",
    "stages += [assembler]\n",
    "\n",
    "#pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df37dc3a-ef9f-42f8-a850-dda545797cb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Fit the pipeline with dataframes\n",
    "pipeline_model_train = pipeline.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cdb4a2c-8023-48b6-8ece-c5a0686bc7cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Apply pipeline to dataframes\n",
    "train_df= pipeline_model_train.transform(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51745abc-0387-480f-9ca1-e7956fed52b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "#split the data Time period 1: From '2020-01-01' to '2022-10-01'\n",
    "train_data = train_df.filter(\n",
    "    (col(\"tpep_pickup_datetime\") >= \"2020-01-01\") &\n",
    "    (col(\"tpep_pickup_datetime\") < \"2022-10-01\")\n",
    ")\n",
    "\n",
    "# # Time period 2: From '2022-10-01' to '2022-12-31'\n",
    "test_data = train_df.filter(\n",
    "    (col(\"tpep_pickup_datetime\") >= \"2022-10-01\") &\n",
    "    (col(\"tpep_pickup_datetime\") <= \"2022-12-31\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59354285-b5cf-4e3c-916e-0f8d0fcb4061",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#train LinearRegression\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol='features', labelCol='total_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86f90889-4dbd-4e62-b8df-13e64792f9f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#fit the model on training set\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa0af558-4006-4276-99bf-e82d6a66756b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#make pred on train set\n",
    "train_preds = lr_model.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "248380f7-b320-4221-8cb8-761075d003dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+-----+------------------+------------------+------------+------------------+--------------------+------------------+\n|weekday|hour|year|month|  trip_distance_km| trip_duration_min|total_amount|             speed|             Zone_pu|        prediction|\n+-------+----+----+-----+------------------+------------------+------------+------------------+--------------------+------------------+\n|      6|  23|2022|    9|         1.6415268|               7.1|       12.36|13.872057464788734| Little Italy/NoLiTa|12.454592664907238|\n|      6|  23|2022|    9|          2.092142| 9.666666666666666|        11.8|12.985708965517242|      Midtown Center|14.237301304978644|\n|      6|  23|2022|    9|1.6737136000000001|               4.4|       11.62|22.823367272727275|Upper West Side S...|11.145139989509516|\n|      6|  23|2022|    9|          1.448406|              6.45|         9.8|13.473544186046514|                SoHo| 12.05646622503383|\n|      6|  23|2022|    9|         5.8579976|15.183333333333334|       20.76|23.149057475301866|     Lenox Hill West|21.801486748459865|\n|      6|  23|2022|    9|2.2369825999999997|             12.15|        12.8|11.046827654320987|Times Sq/Theatre ...|15.029257043008045|\n|      6|  23|2022|    9|          5.713157|             17.85|        17.8| 19.20388907563025|            Union Sq| 22.37065666372945|\n|      6|  23|2022|    9|         2.7519714| 8.416666666666666|        11.8| 19.61801394059406| Lincoln Square East|14.375329478651679|\n|      6|  23|2022|    9|         25.508039| 34.21666666666667|       57.66| 44.72914778373113|         JFK Airport|  58.2133320384346|\n|      6|  23|2022|    9| 4.473965199999999|17.533333333333335|        16.8|15.310147072243344|Times Sq/Theatre ...|20.006081130363896|\n+-------+----+----+-----+------------------+------------------+------------+------------------+--------------------+------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "#show columns vs pred train\n",
    "train_preds.select(cols_list + ['prediction']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12752cbc-5316-4a46-91c7-8fd75e3e3ff8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#make pred on test set\n",
    "test_preds = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91a8c5a7-4b87-4472-acdd-2cf19f9dae87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n|total_amount|        prediction|\n+------------+------------------+\n|       15.95|15.701707831443684|\n|         9.3|  9.56646138557312|\n|       12.36|14.273423028490015|\n|       12.35|11.865978531893234|\n|         9.1|10.849942833968157|\n|        29.3|  33.9369646988892|\n|        14.3|15.480508290320756|\n|        47.8|  54.3483558177748|\n|       31.01| 35.36487269476879|\n|        19.8|32.443657485823906|\n+------------+------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "#show columns vs pred train\n",
    "test_preds.select([\"total_amount\"] + ['prediction']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "313a1958-69d6-40d1-9206-6d6280cae8ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#evaluate with RMSE\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName='rmse',labelCol='total_amount',predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a34a78b-da7a-493e-91fa-b6ee8d4b19e9",
     "showTitle": true,
     "title": "RMSE"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_train= 188.3974532124786\n"
     ]
    }
   ],
   "source": [
    "#print rmse train\n",
    "rmse_train =evaluator.evaluate(train_preds)\n",
    "print('rmse_train=',rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec666521-9efb-4a37-b934-d42d8b1edd86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_test= 6.059042097969246\n"
     ]
    }
   ],
   "source": [
    "rmse_test =evaluator.evaluate(test_preds)\n",
    "print('rmse_test=',rmse_test)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Part 3 -Linear Regression",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
